# Inference on the regression parameters


---
### Notes and Ideas:
In the Model:
$$Y_{i}=\beta_{0}+\beta_{1}X_{i}+\epsilon_{i}$$
We learnt how to estimate the parameters $\beta_{0}$ and $\beta_{1}$. If this  
was all we wanted to do we could use least square  estimates and not have to make distributional assumptions.  
  
However, in most cases this is not enough and we want to  make certain inferences on the parameters of regression:  
  
1. We are interested in testing for the slope  
2. Testing for the intercept
	1. Implication of Test $\beta\neq 0$ : no CAUSAL relationship  
can be implied
3. Confidence interval for slope 
4. Confidence interval for intercept  
5. Confidence intervals and testing on the mean of Y  
6. Prediction intervals
==For all this it is important to make the assumption that the error $\epsilon$ is distributed normally with mean 0 and standard deviation $\sigma$.==


---

### Key :
- [[MLR - t test and anova]]

---
#### TAGS